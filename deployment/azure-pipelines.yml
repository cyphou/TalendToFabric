# Azure DevOps Pipeline â€” Talend to Fabric Migration CI/CD
# This pipeline deploys Data Factory pipelines and Spark notebooks to Fabric.

trigger:
  branches:
    include:
      - main
      - release/*
  paths:
    include:
      - templates/**
      - output/**

pool:
  vmImage: 'ubuntu-latest'

variables:
  - group: 'fabric-migration-vars'  # Variable group with secrets
  - name: pythonVersion
    value: '3.10'

parameters:
  - name: environment
    displayName: 'Target Environment'
    type: string
    default: 'dev'
    values:
      - dev
      - uat
      - prod
  - name: deployPipelines
    displayName: 'Deploy Data Factory Pipelines'
    type: boolean
    default: true
  - name: deployNotebooks
    displayName: 'Deploy Spark Notebooks'
    type: boolean
    default: true
  - name: runValidation
    displayName: 'Run Post-Deploy Validation'
    type: boolean
    default: true

stages:

# ============================================================
# Stage 1: Build & Validate
# ============================================================
- stage: Build
  displayName: 'Build & Validate Artifacts'
  jobs:
  - job: ValidateArtifacts
    displayName: 'Validate Migration Artifacts'
    steps:
    - task: UsePythonVersion@0
      inputs:
        versionSpec: '$(pythonVersion)'
      displayName: 'Use Python $(pythonVersion)'

    - script: |
        pip install -r parser/requirements.txt
        pip install -r translator/requirements.txt
        pip install -r validation/requirements.txt
      displayName: 'Install dependencies'

    - script: |
        python -m py_compile parser/parse_talend_jobs.py
        python -m py_compile parser/extract_metadata.py
        python -m py_compile parser/generate_inventory.py
        python -m py_compile translator/translate_to_adf.py
        python -m py_compile translator/translate_to_spark.py
        python -m py_compile translator/sql_translator.py
        python -m py_compile validation/row_count_validation.py
        python -m py_compile validation/data_diff_validation.py
      displayName: 'Validate Python scripts'

    - script: |
        python -c "
        import json
        for f in ['mapping/component_map.json', 'mapping/connection_map.json', 'mapping/datatype_map.json', 'config/migration_config.json', 'config/environments.json']:
            with open(f) as fh:
                json.load(fh)
            print(f'Valid: {f}')
        "
      displayName: 'Validate JSON files'

    - task: PublishBuildArtifacts@1
      inputs:
        pathtoPublish: '$(Build.SourcesDirectory)'
        artifactName: 'migration-artifacts'
      displayName: 'Publish artifacts'

# ============================================================
# Stage 2: Deploy to Fabric
# ============================================================
- stage: Deploy
  displayName: 'Deploy to Fabric (${{ parameters.environment }})'
  dependsOn: Build
  condition: succeeded()
  jobs:
  - deployment: DeployToFabric
    displayName: 'Deploy to Fabric Workspace'
    environment: '${{ parameters.environment }}'
    strategy:
      runOnce:
        deploy:
          steps:
          - task: DownloadBuildArtifacts@1
            inputs:
              buildType: 'current'
              downloadType: 'single'
              artifactName: 'migration-artifacts'
              downloadPath: '$(System.ArtifactsDirectory)'

          - task: AzurePowerShell@5
            displayName: 'Deploy Data Factory Pipelines'
            condition: eq('${{ parameters.deployPipelines }}', true)
            inputs:
              azureSubscription: '$(azureServiceConnection)'
              ScriptType: 'FilePath'
              ScriptPath: '$(System.ArtifactsDirectory)/migration-artifacts/deployment/deploy_fabric.ps1'
              ScriptArguments: >
                -Environment ${{ parameters.environment }}
                -WorkspaceId $(fabricWorkspaceId)
                -DeployPipelines
              azurePowerShellVersion: 'LatestVersion'

          - task: AzurePowerShell@5
            displayName: 'Deploy Spark Notebooks'
            condition: eq('${{ parameters.deployNotebooks }}', true)
            inputs:
              azureSubscription: '$(azureServiceConnection)'
              ScriptType: 'FilePath'
              ScriptPath: '$(System.ArtifactsDirectory)/migration-artifacts/deployment/deploy_fabric.ps1'
              ScriptArguments: >
                -Environment ${{ parameters.environment }}
                -WorkspaceId $(fabricWorkspaceId)
                -DeployNotebooks
              azurePowerShellVersion: 'LatestVersion'

# ============================================================
# Stage 3: Validation
# ============================================================
- stage: Validate
  displayName: 'Post-Deploy Validation'
  dependsOn: Deploy
  condition: and(succeeded(), eq('${{ parameters.runValidation }}', true))
  jobs:
  - job: RunValidation
    displayName: 'Run Validation Tests'
    steps:
    - task: UsePythonVersion@0
      inputs:
        versionSpec: '$(pythonVersion)'

    - script: |
        pip install -r validation/requirements.txt
      displayName: 'Install validation dependencies'

    - script: |
        python validation/row_count_validation.py \
          --config config/migration_config.json \
          --output $(Build.ArtifactStagingDirectory)/row_count_results.json
      displayName: 'Run row count validation'

    - task: PublishBuildArtifacts@1
      inputs:
        pathtoPublish: '$(Build.ArtifactStagingDirectory)'
        artifactName: 'validation-results'
      displayName: 'Publish validation results'
